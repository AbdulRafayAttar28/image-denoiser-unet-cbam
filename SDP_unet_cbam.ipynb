{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNdv4UYorn7Q/v3yedot5KK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVC3bvsu3A3e","executionInfo":{"status":"ok","timestamp":1759055762103,"user_tz":-330,"elapsed":11903,"user":{"displayName":"Sadiq Pathan","userId":"17880434745985997358"}},"outputId":"f0add41b-06e9-479b-84a6-092ac6fb2b6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.21.4)\n","Collecting pytorch-ssim\n","  Downloading pytorch_ssim-0.1.tar.gz (1.4 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.2.1)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.9)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.38.0)\n","Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.8.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","Building wheels for collected packages: pytorch-ssim\n","  Building wheel for pytorch-ssim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytorch-ssim: filename=pytorch_ssim-0.1-py3-none-any.whl size=2006 sha256=69ec432f75f3f84bd97046b1c3de01db5916ab7981ddb1ab22f83becc5b72a95\n","  Stored in directory: /root/.cache/pip/wheels/54/a0/11/99f86224e71729ed9ef0c4ffe1b795807ad5f44bde19bc66f9\n","Successfully built pytorch-ssim\n","Installing collected packages: pytorch-ssim\n","Successfully installed pytorch-ssim-0.1\n"]}],"source":["!pip install wandb pytorch-ssim\n"]},{"cell_type":"code","source":["!pip install kagglehub\n","!pip install kaggle\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DRkNjrdp3MsN","executionInfo":{"status":"ok","timestamp":1759055780054,"user_tz":-330,"elapsed":14439,"user":{"displayName":"Sadiq Pathan","userId":"17880434745985997358"}},"outputId":"6fdb2b10-da3d-484e-9c01-d5ccd7fd1e20"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.8.3)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.8.3)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"]}]},{"cell_type":"code","source":["import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"rajat95gupta/smartphone-image-denoising-dataset\")\n","\n","print(\"Path to dataset files:\", path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3x80_Uwo3O1I","executionInfo":{"status":"ok","timestamp":1759055907155,"user_tz":-330,"elapsed":123520,"user":{"displayName":"Sadiq Pathan","userId":"17880434745985997358"}},"outputId":"e6a55bb4-2dbc-4c61-cfd4-59c78039aa39"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/rajat95gupta/smartphone-image-denoising-dataset?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6.16G/6.16G [00:57<00:00, 114MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1\n"]}]},{"cell_type":"code","source":["import os\n","\n","dataset_root = \"/root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1\"\n","\n","# List all files and subfolders\n","for root, dirs, files in os.walk(dataset_root):\n","    print(\"DIR:\", root)\n","    for d in dirs:\n","        print(\"  ├─ Subdir:\", d)\n","    for f in files[:5]:  # just show a few files\n","        print(\"  └─ File:\", f)\n","    print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zkFm07nY3Rik","executionInfo":{"status":"ok","timestamp":1759055914898,"user_tz":-330,"elapsed":472,"user":{"displayName":"Sadiq Pathan","userId":"17880434745985997358"}},"outputId":"6f21112b-6c79-4d9b-b6ae-e521cd9b01a9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1\n","  ├─ Subdir: SIDD_Small_sRGB_Only\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only\n","  ├─ Subdir: Data\n","  └─ File: _ReadMe.txt\n","  └─ File: Scene_Instances.txt\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data\n","  ├─ Subdir: 0042_002_IP_01600_03100_5500_N\n","  ├─ Subdir: 0066_003_GP_00100_00200_3200_L\n","  ├─ Subdir: 0097_005_N6_03200_02000_3200_L\n","  ├─ Subdir: 0118_006_N6_00100_00025_3200_L\n","  ├─ Subdir: 0114_005_IP_00100_00200_5500_N\n","  ├─ Subdir: 0040_002_IP_00800_02000_5500_L\n","  ├─ Subdir: 0115_005_IP_00400_00750_5500_N\n","  ├─ Subdir: 0013_001_S6_03200_01250_3200_L\n","  ├─ Subdir: 0048_002_N6_00100_00100_5500_L\n","  ├─ Subdir: 0034_002_GP_00100_00160_3200_N\n","  ├─ Subdir: 0159_007_IP_00100_00100_3200_L\n","  ├─ Subdir: 0191_008_IP_01600_01600_3200_N\n","  ├─ Subdir: 0185_008_IP_00400_00400_3200_L\n","  ├─ Subdir: 0081_004_S6_00800_00160_4400_L\n","  ├─ Subdir: 0105_005_GP_00100_00100_4400_N\n","  ├─ Subdir: 0017_001_GP_00100_00060_5500_N\n","  ├─ Subdir: 0111_005_IP_00400_00400_5500_L\n","  ├─ Subdir: 0186_008_IP_00800_00800_3200_L\n","  ├─ Subdir: 0033_001_IP_00100_00160_3200_N\n","  ├─ Subdir: 0190_008_IP_00800_00800_3200_N\n","  ├─ Subdir: 0003_001_S6_00100_00060_3200_H\n","  ├─ Subdir: 0068_003_IP_00200_00400_3200_N\n","  ├─ Subdir: 0080_004_S6_00200_00050_3200_N\n","  ├─ Subdir: 0078_004_G4_00200_00050_3200_N\n","  ├─ Subdir: 0005_001_S6_00100_00060_4400_N\n","  ├─ Subdir: 0050_002_N6_03200_03200_5500_L\n","  ├─ Subdir: 0035_002_GP_00800_00350_3200_N\n","  ├─ Subdir: 0084_004_GP_00200_00100_4400_N\n","  ├─ Subdir: 0164_007_IP_00400_00400_3200_N\n","  ├─ Subdir: 0197_009_IP_00100_00200_5500_L\n","  ├─ Subdir: 0016_001_S6_03200_01600_5500_N\n","  ├─ Subdir: 0120_006_N6_01600_00400_3200_L\n","  ├─ Subdir: 0189_008_IP_00400_00400_3200_N\n","  ├─ Subdir: 0157_007_GP_01600_01600_5500_N\n","  ├─ Subdir: 0193_009_IP_00800_02000_3200_N\n","  ├─ Subdir: 0121_006_N6_03200_01000_3200_L\n","  ├─ Subdir: 0154_007_S6_00400_00400_5500_L\n","  ├─ Subdir: 0167_008_N6_00100_00050_4400_L\n","  ├─ Subdir: 0055_003_N6_00800_01000_5500_N\n","  ├─ Subdir: 0101_005_S6_00100_00050_4400_L\n","  ├─ Subdir: 0135_006_IP_00400_00400_5500_N\n","  ├─ Subdir: 0137_006_IP_01600_01600_5500_N\n","  ├─ Subdir: 0089_004_IP_00500_00250_5500_N\n","  ├─ Subdir: 0032_001_IP_00800_01000_3200_N\n","  ├─ Subdir: 0065_003_GP_10000_08460_4400_N\n","  ├─ Subdir: 0138_006_IP_00100_00100_3200_L\n","  ├─ Subdir: 0200_010_GP_01600_03200_5500_N\n","  ├─ Subdir: 0169_008_N6_00800_00400_4400_L\n","  ├─ Subdir: 0182_008_GP_03200_03200_5500_N\n","  ├─ Subdir: 0123_006_G4_00400_00160_3200_N\n","  ├─ Subdir: 0076_004_N6_03200_00320_3200_L\n","  ├─ Subdir: 0060_003_S6_00100_00100_4400_L\n","  ├─ Subdir: 0199_010_GP_00800_01600_5500_N\n","  ├─ Subdir: 0006_001_S6_00100_00060_4400_H\n","  ├─ Subdir: 0075_004_N6_00800_00080_3200_L\n","  ├─ Subdir: 0087_004_GP_00800_00640_5500_L\n","  ├─ Subdir: 0113_005_IP_01600_01520_5500_L\n","  ├─ Subdir: 0198_010_GP_00100_00200_5500_N\n","  ├─ Subdir: 0117_005_IP_01600_04160_5500_N\n","  ├─ Subdir: 0179_008_S6_03200_00800_5500_L\n","  ├─ Subdir: 0195_009_IP_01600_04000_5500_L\n","  ├─ Subdir: 0173_008_G4_00400_00400_4400_N\n","  ├─ Subdir: 0108_005_GP_06400_06400_4400_N\n","  ├─ Subdir: 0136_006_IP_00800_00800_5500_N\n","  ├─ Subdir: 0160_007_IP_00400_00400_3200_L\n","  ├─ Subdir: 0147_007_G4_00100_00100_4400_L\n","  ├─ Subdir: 0028_001_IP_00100_00160_5500_N\n","  ├─ Subdir: 0059_003_G4_00800_01000_5500_L\n","  ├─ Subdir: 0170_008_N6_01600_00800_4400_L\n","  ├─ Subdir: 0152_007_S6_01600_01600_5500_L\n","  ├─ Subdir: 0161_007_IP_00800_00800_3200_L\n","  ├─ Subdir: 0073_003_IP_00200_01000_5500_L\n","  ├─ Subdir: 0122_006_G4_00100_00050_3200_N\n","  ├─ Subdir: 0166_007_IP_01600_01600_3200_N\n","  ├─ Subdir: 0077_004_G4_00100_00025_3200_N\n","  ├─ Subdir: 0146_007_N6_00400_00400_4400_N\n","  ├─ Subdir: 0069_003_IP_01000_02000_3200_N\n","  ├─ Subdir: 0188_008_IP_00100_00100_3200_N\n","  ├─ Subdir: 0150_007_S6_00100_00100_5500_L\n","  ├─ Subdir: 0163_007_IP_00100_00100_3200_N\n","  ├─ Subdir: 0008_001_S6_00100_00100_5500_N\n","  ├─ Subdir: 0172_008_G4_00100_00100_4400_N\n","  ├─ Subdir: 0106_005_GP_00400_00400_4400_N\n","  ├─ Subdir: 0194_009_IP_01600_04000_3200_N\n","  ├─ Subdir: 0178_008_S6_01600_00400_5500_L\n","  ├─ Subdir: 0165_007_IP_00800_00800_3200_N\n","  ├─ Subdir: 0020_001_GP_00800_00350_5500_N\n","  ├─ Subdir: 0102_005_S6_00400_00200_4400_L\n","  ├─ Subdir: 0144_007_N6_01600_01600_4400_N\n","  ├─ Subdir: 0181_008_GP_00800_00800_5500_N\n","  ├─ Subdir: 0094_005_N6_00100_00050_3200_L\n","  ├─ Subdir: 0070_003_IP_02000_04000_3200_N\n","  ├─ Subdir: 0044_002_IP_00100_00180_5500_N\n","  ├─ Subdir: 0140_006_IP_00800_00800_3200_L\n","  ├─ Subdir: 0057_003_G4_00100_00125_5500_L\n","  ├─ Subdir: 0051_002_S6_00100_00060_5500_N\n","  ├─ Subdir: 0104_005_S6_03200_01600_4400_L\n","  ├─ Subdir: 0038_002_GP_00800_00640_3200_L\n","  ├─ Subdir: 0004_001_S6_00100_00060_4400_L\n","  ├─ Subdir: 0192_009_IP_00100_00200_3200_N\n","  ├─ Subdir: 0064_003_GP_01600_01600_4400_N\n","  ├─ Subdir: 0092_004_IP_00640_00125_3200_L\n","  ├─ Subdir: 0015_001_S6_03200_01600_5500_L\n","  ├─ Subdir: 0083_004_GP_00050_00020_4400_N\n","  ├─ Subdir: 0010_001_S6_00800_00350_3200_N\n","  ├─ Subdir: 0025_001_G4_00100_00060_5500_L\n","  ├─ Subdir: 0036_002_GP_06400_03200_3200_N\n","  ├─ Subdir: 0180_008_GP_00100_00100_5500_N\n","  ├─ Subdir: 0090_004_IP_01600_00750_5500_N\n","  ├─ Subdir: 0098_005_G4_00100_00050_3200_N\n","  ├─ Subdir: 0177_008_S6_00800_00200_5500_L\n","  ├─ Subdir: 0134_006_IP_00100_00100_5500_N\n","  ├─ Subdir: 0096_005_N6_01600_01000_3200_L\n","  ├─ Subdir: 0030_001_IP_01600_02000_5500_N\n","  ├─ Subdir: 0126_006_S6_00400_00200_4400_L\n","  ├─ Subdir: 0072_003_IP_01000_02000_5500_L\n","  ├─ Subdir: 0145_007_N6_03200_03200_4400_N\n","  ├─ Subdir: 0029_001_IP_00800_01000_5500_N\n","  ├─ Subdir: 0110_005_IP_00100_00100_5500_L\n","  ├─ Subdir: 0155_007_GP_00100_00100_5500_N\n","  ├─ Subdir: 0043_002_IP_00800_01520_5500_N\n","  ├─ Subdir: 0045_002_G4_00100_00060_3200_L\n","  ├─ Subdir: 0086_004_GP_00100_00100_5500_L\n","  ├─ Subdir: 0133_006_GP_00800_01600_5500_L\n","  ├─ Subdir: 0168_008_N6_00400_00200_4400_L\n","  ├─ Subdir: 0149_007_G4_00800_00800_4400_L\n","  ├─ Subdir: 0116_005_IP_00800_01520_5500_N\n","  ├─ Subdir: 0127_006_S6_01600_00800_4400_L\n","  ├─ Subdir: 0018_001_GP_00100_00160_5500_L\n","  ├─ Subdir: 0139_006_IP_00200_00200_3200_L\n","  ├─ Subdir: 0054_003_N6_00100_00160_5500_N\n","  ├─ Subdir: 0023_001_N6_00800_00350_5500_N\n","  ├─ Subdir: 0052_002_S6_01600_01000_5500_N\n","  ├─ Subdir: 0012_001_S6_00800_00500_5500_N\n","  ├─ Subdir: 0007_001_S6_00100_00100_5500_L\n","  ├─ Subdir: 0001_001_S6_00100_00060_3200_L\n","  ├─ Subdir: 0130_006_GP_00400_00400_4400_N\n","  ├─ Subdir: 0142_007_N6_00100_00100_4400_N\n","  ├─ Subdir: 0175_008_S6_00100_00025_5500_L\n","  ├─ Subdir: 0039_002_IP_00100_00180_5500_L\n","  ├─ Subdir: 0132_006_GP_00100_00200_5500_L\n","  ├─ Subdir: 0047_002_G4_00800_00640_3200_L\n","  ├─ Subdir: 0011_001_S6_00800_00500_5500_L\n","  ├─ Subdir: 0022_001_N6_00100_00060_5500_N\n","  ├─ Subdir: 0156_007_GP_00800_00800_5500_N\n","  ├─ Subdir: 0125_006_S6_00100_00050_4400_L\n","  ├─ Subdir: 0091_004_IP_00320_00080_3200_L\n","  ├─ Subdir: 0063_003_GP_00100_00100_4400_N\n","  ├─ Subdir: 0196_009_IP_00800_02000_5500_L\n","  ├─ Subdir: 0014_001_S6_03200_01250_3200_N\n","  ├─ Subdir: 0184_008_IP_00100_00100_3200_L\n","  ├─ Subdir: 0027_001_G4_00800_00350_5500_L\n","  ├─ Subdir: 0099_005_G4_00400_00200_3200_N\n","  ├─ Subdir: 0107_005_GP_01600_01600_4400_N\n","  ├─ Subdir: 0062_003_S6_03200_02500_4400_L\n","  ├─ Subdir: 0088_004_IP_00100_00050_5500_N\n","  ├─ Subdir: 0129_006_GP_00100_00100_4400_N\n","  ├─ Subdir: 0019_001_GP_00800_00640_5500_L\n","  ├─ Subdir: 0002_001_S6_00100_00020_3200_N\n","  ├─ Subdir: 0151_007_S6_00800_00800_5500_L\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0042_002_IP_01600_03100_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0066_003_GP_00100_00200_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0097_005_N6_03200_02000_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0118_006_N6_00100_00025_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0114_005_IP_00100_00200_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0040_002_IP_00800_02000_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0115_005_IP_00400_00750_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0013_001_S6_03200_01250_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0048_002_N6_00100_00100_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0034_002_GP_00100_00160_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0159_007_IP_00100_00100_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0191_008_IP_01600_01600_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0185_008_IP_00400_00400_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0081_004_S6_00800_00160_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0105_005_GP_00100_00100_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0017_001_GP_00100_00060_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0111_005_IP_00400_00400_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0186_008_IP_00800_00800_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0033_001_IP_00100_00160_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0190_008_IP_00800_00800_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0003_001_S6_00100_00060_3200_H\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0068_003_IP_00200_00400_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0080_004_S6_00200_00050_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0078_004_G4_00200_00050_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0005_001_S6_00100_00060_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0050_002_N6_03200_03200_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0035_002_GP_00800_00350_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0084_004_GP_00200_00100_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0164_007_IP_00400_00400_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0197_009_IP_00100_00200_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0016_001_S6_03200_01600_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0120_006_N6_01600_00400_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0189_008_IP_00400_00400_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0157_007_GP_01600_01600_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0193_009_IP_00800_02000_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0121_006_N6_03200_01000_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0154_007_S6_00400_00400_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0167_008_N6_00100_00050_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0055_003_N6_00800_01000_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0101_005_S6_00100_00050_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0135_006_IP_00400_00400_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0137_006_IP_01600_01600_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0089_004_IP_00500_00250_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0032_001_IP_00800_01000_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0065_003_GP_10000_08460_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0138_006_IP_00100_00100_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0200_010_GP_01600_03200_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0169_008_N6_00800_00400_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0182_008_GP_03200_03200_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0123_006_G4_00400_00160_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0076_004_N6_03200_00320_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0060_003_S6_00100_00100_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0199_010_GP_00800_01600_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0006_001_S6_00100_00060_4400_H\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0075_004_N6_00800_00080_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0087_004_GP_00800_00640_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0113_005_IP_01600_01520_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0198_010_GP_00100_00200_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0117_005_IP_01600_04160_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0179_008_S6_03200_00800_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0195_009_IP_01600_04000_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0173_008_G4_00400_00400_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0108_005_GP_06400_06400_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0136_006_IP_00800_00800_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0160_007_IP_00400_00400_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0147_007_G4_00100_00100_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0028_001_IP_00100_00160_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0059_003_G4_00800_01000_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0170_008_N6_01600_00800_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0152_007_S6_01600_01600_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0161_007_IP_00800_00800_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0073_003_IP_00200_01000_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0122_006_G4_00100_00050_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0166_007_IP_01600_01600_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0077_004_G4_00100_00025_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0146_007_N6_00400_00400_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0069_003_IP_01000_02000_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0188_008_IP_00100_00100_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0150_007_S6_00100_00100_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0163_007_IP_00100_00100_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0008_001_S6_00100_00100_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0172_008_G4_00100_00100_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0106_005_GP_00400_00400_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0194_009_IP_01600_04000_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0178_008_S6_01600_00400_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0165_007_IP_00800_00800_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0020_001_GP_00800_00350_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0102_005_S6_00400_00200_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0144_007_N6_01600_01600_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0181_008_GP_00800_00800_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0094_005_N6_00100_00050_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0070_003_IP_02000_04000_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0044_002_IP_00100_00180_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0140_006_IP_00800_00800_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0057_003_G4_00100_00125_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0051_002_S6_00100_00060_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0104_005_S6_03200_01600_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0038_002_GP_00800_00640_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0004_001_S6_00100_00060_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0192_009_IP_00100_00200_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0064_003_GP_01600_01600_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0092_004_IP_00640_00125_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0015_001_S6_03200_01600_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0083_004_GP_00050_00020_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0010_001_S6_00800_00350_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0025_001_G4_00100_00060_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0036_002_GP_06400_03200_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0180_008_GP_00100_00100_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0090_004_IP_01600_00750_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0098_005_G4_00100_00050_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0177_008_S6_00800_00200_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0134_006_IP_00100_00100_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0096_005_N6_01600_01000_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0030_001_IP_01600_02000_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0126_006_S6_00400_00200_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0072_003_IP_01000_02000_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0145_007_N6_03200_03200_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0029_001_IP_00800_01000_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0110_005_IP_00100_00100_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0155_007_GP_00100_00100_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0043_002_IP_00800_01520_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0045_002_G4_00100_00060_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0086_004_GP_00100_00100_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0133_006_GP_00800_01600_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0168_008_N6_00400_00200_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0149_007_G4_00800_00800_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0116_005_IP_00800_01520_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0127_006_S6_01600_00800_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0018_001_GP_00100_00160_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0139_006_IP_00200_00200_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0054_003_N6_00100_00160_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0023_001_N6_00800_00350_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0052_002_S6_01600_01000_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0012_001_S6_00800_00500_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0007_001_S6_00100_00100_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0001_001_S6_00100_00060_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0130_006_GP_00400_00400_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0142_007_N6_00100_00100_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0175_008_S6_00100_00025_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0039_002_IP_00100_00180_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0132_006_GP_00100_00200_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0047_002_G4_00800_00640_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0011_001_S6_00800_00500_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0022_001_N6_00100_00060_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0156_007_GP_00800_00800_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0125_006_S6_00100_00050_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0091_004_IP_00320_00080_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0063_003_GP_00100_00100_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0196_009_IP_00800_02000_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0014_001_S6_03200_01250_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0184_008_IP_00100_00100_3200_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0027_001_G4_00800_00350_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0099_005_G4_00400_00200_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0107_005_GP_01600_01600_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0062_003_S6_03200_02500_4400_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0088_004_IP_00100_00050_5500_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0129_006_GP_00100_00100_4400_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0019_001_GP_00800_00640_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0002_001_S6_00100_00020_3200_N\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n","DIR: /root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data/0151_007_S6_00800_00800_5500_L\n","  └─ File: NOISY_SRGB_010.PNG\n","  └─ File: GT_SRGB_010.PNG\n","\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","source_data_dir = \"/root/.cache/kagglehub/datasets/rajat95gupta/smartphone-image-denoising-dataset/versions/1/SIDD_Small_sRGB_Only/Data\"\n","output_noisy_dir = \"/content/SIDD/input\"\n","output_clean_dir = \"/content/SIDD/target\"\n","\n","# Create target folders\n","os.makedirs(output_noisy_dir, exist_ok=True)\n","os.makedirs(output_clean_dir, exist_ok=True)\n","\n","# Initialize image counter\n","copied = 0\n","\n","# Walk through each scene directory\n","for scene_dir in sorted(os.listdir(source_data_dir)):\n","    scene_path = os.path.join(source_data_dir, scene_dir)\n","    if not os.path.isdir(scene_path):\n","        continue\n","\n","    # Get list of image files\n","    files = sorted(os.listdir(scene_path))\n","\n","    # Group noisy and clean images\n","    noisy_files = [f for f in files if \"NOISY\" in f.upper()]\n","    clean_files = [f for f in files if \"GT\" in f.upper()]\n","\n","    # Sort to ensure alignment\n","    noisy_files.sort()\n","    clean_files.sort()\n","\n","    # Copy files\n","    for noisy_file, clean_file in zip(noisy_files, clean_files):\n","        shutil.copy(os.path.join(scene_path, noisy_file), os.path.join(output_noisy_dir, f\"{copied:05d}.png\"))\n","        shutil.copy(os.path.join(scene_path, clean_file), os.path.join(output_clean_dir, f\"{copied:05d}.png\"))\n","        copied += 1\n","\n","print(f\"Copied {copied} noisy/clean image pairs.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0VXgDsq3T5E","executionInfo":{"status":"ok","timestamp":1759055982041,"user_tz":-330,"elapsed":60815,"user":{"displayName":"Sadiq Pathan","userId":"17880434745985997358"}},"outputId":"e0085904-eee2-45ba-a06c-1103729c22ab"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Copied 160 noisy/clean image pairs.\n"]}]},{"cell_type":"code","source":["# denoise_prune_export.py\n","import os\n","import glob\n","from math import exp\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from PIL import Image\n","import torchvision.transforms as T\n","\n","import torch.nn.utils.prune as prune\n","import wandb  # Import wandb\n","\n","# -----------------------\n","# Dataset (same as you)\n","# -----------------------\n","class SIDD_DenoiseDataset(Dataset):\n","    def __init__(self, noisy_dir, clean_dir, transform=None):\n","        self.noisy_images = sorted(glob.glob(os.path.join(noisy_dir, \"*.png\")))\n","        self.clean_images = sorted(glob.glob(os.path.join(clean_dir, \"*.png\")))\n","        self.transform = transform\n","        assert len(self.noisy_images) == len(self.clean_images), \"Mismatch in noisy and clean image counts\"\n","\n","    def __len__(self):\n","        return len(self.noisy_images)\n","\n","    def __getitem__(self, idx):\n","        noisy = Image.open(self.noisy_images[idx]).convert(\"RGB\")\n","        clean = Image.open(self.clean_images[idx]).convert(\"RGB\")\n","        if self.transform:\n","            noisy = self.transform(noisy)\n","            clean = self.transform(clean)\n","        return noisy.clamp(0., 1.), clean\n","\n","# -----------------------\n","# Lightweight building blocks\n","# -----------------------\n","class ChannelAttention(nn.Module):\n","    def __init__(self, in_planes, ratio=8):\n","        super().__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc = nn.Sequential(\n","            nn.Conv2d(in_planes, max(in_planes // ratio, 4), 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(max(in_planes // ratio, 4), in_planes, 1)\n","        )\n","        self.sigmoid = nn.Sigmoid()\n","    def forward(self, x):\n","        return x * self.sigmoid(self.fc(self.avg_pool(x)))\n","\n","class SpatialAttention(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3)\n","        self.sigmoid = nn.Sigmoid()\n","    def forward(self, x):\n","        max_pool = torch.max(x, dim=1, keepdim=True)[0]\n","        avg_pool = torch.mean(x, dim=1, keepdim=True)\n","        pooled = torch.cat([avg_pool, max_pool], dim=1)\n","        return self.sigmoid(self.conv(pooled))\n","\n","class CBAM(nn.Module):\n","    def __init__(self, in_channels):\n","        super().__init__()\n","        self.ca = ChannelAttention(in_channels)\n","        self.sa = SpatialAttention()\n","    def forward(self, x):\n","        return self.ca(x) * self.sa(x)\n","\n","def conv_block(in_ch, out_ch, separable=False):\n","    # Use regular convs but keep channels small for edge\n","    if separable:\n","        # depthwise separable conv (lightweight)\n","        return nn.Sequential(\n","            nn.Conv2d(in_ch, in_ch, kernel_size=3, padding=1, groups=in_ch),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_ch, out_ch, kernel_size=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            CBAM(out_ch)\n","        )\n","    else:\n","        return nn.Sequential(\n","            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            CBAM(out_ch)\n","        )\n","\n","class UNetStage(nn.Module):\n","    def __init__(self, in_ch=3, base_ch=32, separable=False):\n","        super().__init__()\n","        self.enc1 = conv_block(in_ch, base_ch, separable=separable)\n","        self.enc2 = conv_block(base_ch, base_ch*2, separable=separable)\n","        self.enc3 = conv_block(base_ch*2, base_ch*4, separable=separable)\n","        self.pool = nn.MaxPool2d(2)\n","        self.dec2 = conv_block(base_ch*4+base_ch*2, base_ch*2, separable=separable)\n","        self.dec1 = conv_block(base_ch*2+base_ch, base_ch, separable=separable)\n","        self.final = nn.Conv2d(base_ch, 3, kernel_size=1)\n","    def forward(self, x):\n","        e1 = self.enc1(x)\n","        e2 = self.enc2(self.pool(e1))\n","        e3 = self.enc3(self.pool(e2))\n","        d2 = self.dec2(torch.cat([F.interpolate(e3, size=e2.shape[-2:], mode=\"bilinear\", align_corners=False), e2], dim=1))\n","        d1 = self.dec1(torch.cat([F.interpolate(d2, size=e1.shape[-2:], mode=\"bilinear\", align_corners=False), e1], dim=1))\n","        return self.final(d1)\n","\n","class RefinementModule(nn.Module):\n","    \"\"\"\n","    Lightweight refinement module that enhances details.\n","    This does NOT change spatial resolution (no upscaling). For an SR-like effect,\n","    it uses residual convs and channel attention to boost high-frequency details.\n","    \"\"\"\n","    def __init__(self, channels=3, hidden=64):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Conv2d(channels, hidden, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(hidden, hidden, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(hidden, channels, kernel_size=3, padding=1)\n","        )\n","        self.ca = ChannelAttention(channels)\n","    def forward(self, x):\n","        res = self.net(x)\n","        out = x + res\n","        out = self.ca(out)\n","        return out\n","\n","# -----------------------\n","# 2-stage MultiStage Restoration Net (lightweight)\n","# -----------------------\n","class MultiStageRestorationNet(nn.Module):\n","    def __init__(self, in_ch=3, base_ch=32, separable=False):\n","        super().__init__()\n","        self.stage1 = UNetStage(in_ch, base_ch=base_ch, separable=separable)\n","        self.stage2 = UNetStage(in_ch, base_ch=base_ch, separable=separable)\n","        self.refine = RefinementModule(channels=3, hidden=64)\n","\n","    def forward(self, x):\n","        s1 = self.stage1(x)\n","        s2 = self.stage2(x - s1) + s1\n","        out = self.refine(s2)\n","        # clamp to valid range\n","        return out.clamp(0., 1.)\n","\n","# -----------------------\n","# SSIM/PSNR utilities (kept similar to yours, minor fix to PSNR)\n","# -----------------------\n","def create_window(window_size, channel):\n","    def gaussian(window_size, sigma):\n","        g = torch.Tensor([exp(-(x-window_size//2)**2/(2*sigma**2)) for x in range(window_size)])\n","        return g/g.sum()\n","    _1D = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D = _1D.mul(_1D.t()).unsqueeze(0).unsqueeze(0)\n","    return _2D.expand(channel, 1, window_size, window_size).contiguous()\n","\n","def _ssim(img1, img2, window, window_size, channel, size_average=True):\n","    mu1 = F.conv2d(img1, window, padding=window_size//2, groups=channel)\n","    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channel)\n","    mu1_sq, mu2_sq, mu1_mu2 = mu1**2, mu2**2, mu1*mu2\n","    sigma1_sq = F.conv2d(img1*img1, window, padding=window_size//2, groups=channel) - mu1_sq\n","    sigma2_sq = F.conv2d(img2*img2, window, padding=window_size//2, groups=channel) - mu2_sq\n","    sigma12 = F.conv2d(img1*img2, window, padding=window_size//2, groups=channel) - mu1_mu2\n","    C1, C2 = 0.01**2, 0.03**2\n","    ssim_map = ((2*mu1_mu2+C1)*(2*sigma12+C2))/((mu1_sq+mu2_sq+C1+1e-8)*(sigma1_sq+sigma2_sq+C2+1e-8))\n","    return ssim_map.mean() if size_average else ssim_map.mean([2,3]).mean(1)\n","\n","def ssim_loss(output, target, window_size=11):\n","    (_, c, _, _) = output.size()\n","    window = create_window(window_size, c).to(output.device)\n","    return 1 - _ssim(output, target, window, window_size, c, True)\n","\n","def psnr(output, target):\n","    mse = F.mse_loss(output, target, reduction=\"mean\")\n","    # make sure numerical stability; if mse==0 -> very large PSNR\n","    if mse.item() == 0:\n","        return torch.tensor(100.0, device=output.device)\n","    return 10.0 * torch.log10(1.0 / mse)\n","\n","# -----------------------\n","# Pruning utilities\n","# -----------------------\n","def apply_global_unstructured_pruning(model, amount=0.5):\n","    \"\"\"\n","    Globally prune all Conv2d weight tensors by L1 magnitude.\n","    amount: fraction (0.0 - 1.0) of connections to prune globally.\n","    \"\"\"\n","    parameters_to_prune = []\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Conv2d):\n","            parameters_to_prune.append((module, \"weight\"))\n","\n","    print(f\"Applying global unstructured L1 pruning to {len(parameters_to_prune)} conv layers with amount={amount}\")\n","    prune.global_unstructured(\n","        parameters_to_prune,\n","        pruning_method=prune.L1Unstructured,\n","        amount=amount,\n","    )\n","\n","def remove_pruning_reparametrization(model):\n","    \"\"\"\n","    Convert pruned parameters (which are currently masked) into permanent sparse params by removing\n","    the pruning reparametrization. After this, the model weights reflect pruning and masks are gone.\n","    \"\"\"\n","    for module in model.modules():\n","        if isinstance(module, nn.Conv2d):\n","            try:\n","                prune.remove(module, \"weight\")\n","            except Exception:\n","                pass  # some modules may not be pruned\n","\n","# -----------------------\n","# Training / Fine-tune loops\n","# -----------------------\n","def train_one_epoch(model, dataloader, opt, device, epoch):\n","    model.train()\n","    total_loss = 0.0\n","    total_psnr = 0.0\n","    total_l1 = 0.0\n","    total_ssim = 0.0\n","    total_mse = 0.0\n","\n","    for noisy, clean in tqdm(dataloader, desc=\"Train\"):\n","        noisy = noisy.to(device)\n","        clean = clean.to(device)\n","        out = model(noisy)\n","        l1 = F.l1_loss(out, clean)\n","        ssim_l = ssim_loss(out, clean)\n","        # small MSE term to stabilize refinement\n","        mse = F.mse_loss(out, clean)\n","        loss = l1 + 0.15 * ssim_l + 0.01 * mse\n","\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","\n","        total_loss += loss.item()\n","        total_psnr += psnr(out, clean).item()\n","        total_l1 += l1.item()\n","        total_ssim += ssim_l.item()\n","        total_mse += mse.item()\n","\n","    avg_loss = total_loss / len(dataloader)\n","    avg_psnr = total_psnr / len(dataloader)\n","    avg_l1 = total_l1 / len(dataloader)\n","    avg_ssim = total_ssim / len(dataloader)\n","    avg_mse = total_mse / len(dataloader)\n","\n","    return avg_loss, avg_psnr, avg_l1, avg_ssim, avg_mse\n","\n","def validate(model, dataloader, device, epoch):\n","    model.eval()\n","    total_loss = 0.0\n","    total_psnr = 0.0\n","    total_l1 = 0.0\n","    total_ssim = 0.0\n","    total_mse = 0.0\n","\n","    with torch.no_grad():\n","        for noisy, clean in tqdm(dataloader, desc=\"Val\"):\n","            noisy = noisy.to(device)\n","            clean = clean.to(device)\n","            out = model(noisy)\n","            l1 = F.l1_loss(out, clean)\n","            ssim_l = ssim_loss(out, clean)\n","            mse = F.mse_loss(out, clean)\n","            loss = l1 + 0.15 * ssim_l + 0.01 * mse\n","\n","            total_loss += loss.item()\n","            total_psnr += psnr(out, clean).item()\n","            total_l1 += l1.item()\n","            total_ssim += ssim_l.item()\n","            total_mse += mse.item()\n","\n","    avg_loss = total_loss / len(dataloader)\n","    avg_psnr = total_psnr / len(dataloader)\n","    avg_l1 = total_l1 / len(dataloader)\n","    avg_ssim = total_ssim / len(dataloader)\n","    avg_mse = total_mse / len(dataloader)\n","\n","    return avg_loss, avg_psnr, avg_l1, avg_ssim, avg_mse\n","\n","# -----------------------\n","# Main training + pruning + fine-tune + export\n","# -----------------------\n","def main():\n","    # ---- config ----\n","    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    NOISY_DIR = \"/content/SIDD/input\"\n","    CLEAN_DIR = \"/content/SIDD/target\"\n","    SAVE_PATH = \"/content/checkpoints_pruned\"\n","    os.makedirs(SAVE_PATH, exist_ok=True)\n","\n","    EPOCHS = 40               # 40 epochs of training before pruning\n","    FINETUNE_EPOCHS = 8       # epochs to fine-tune after pruning\n","    BATCH_SIZE = 8\n","    LR = 2e-4\n","    BASE_CH = 32              # smaller base channels for edge\n","    SEPARABLE = False         # set True to use depthwise-separable convs in conv_block\n","    PRUNE_AMOUNT = 0.5        # fraction of weights to prune globally\n","    BEST_PSNR = 0.0\n","\n","    # ---- Initialize wandb ----\n","    wandb.init(\n","        project=\"sdp_project2\",\n","        config={\n","            \"epochs\": EPOCHS,\n","            \"finetune_epochs\": FINETUNE_EPOCHS,\n","            \"batch_size\": BATCH_SIZE,\n","            \"learning_rate\": LR,\n","            \"base_channels\": BASE_CH,\n","            \"separable\": SEPARABLE,\n","            \"prune_amount\": PRUNE_AMOUNT,\n","            \"device\": DEVICE,\n","            \"model\": \"MultiStageRestorationNet\",\n","            \"dataset\": \"SIDD\"\n","        },\n","        name=\"40_epochs_denoise_prune\"\n","    )\n","\n","    # ---- data ----\n","    transform = T.Compose([T.Resize((256, 256)), T.ToTensor()])\n","    dataset = SIDD_DenoiseDataset(noisy_dir=NOISY_DIR, clean_dir=CLEAN_DIR, transform=transform)\n","    if len(dataset) == 0:\n","        raise RuntimeError(\"Dataset appears empty; check paths.\")\n","\n","    train_size = int(0.9 * len(dataset))\n","    val_size = len(dataset) - train_size\n","    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n","\n","    # ---- model / optimizer ----\n","    model = MultiStageRestorationNet(in_ch=3, base_ch=BASE_CH, separable=SEPARABLE).to(DEVICE)\n","    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n","\n","    # Log model architecture to wandb\n","    wandb.watch(model, log=\"all\", log_freq=100)\n","\n","    # ---- Checkpoint loading with resilience ----\n","    checkpoint_final = os.path.join(SAVE_PATH, \"final_preprune.pth\")\n","    start_epoch = 0\n","\n","    if os.path.exists(checkpoint_final):\n","        print(\"Found pre-prune checkpoint, loading...\")\n","        try:\n","            checkpoint = torch.load(checkpoint_final, map_location=DEVICE)\n","\n","            # Handle different checkpoint formats\n","            if isinstance(checkpoint, dict):\n","                # New format with state dicts\n","                if 'model_state_dict' in checkpoint:\n","                    model.load_state_dict(checkpoint['model_state_dict'])\n","                    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n","                    start_epoch = checkpoint.get('epoch', 0) + 1\n","                    BEST_PSNR = checkpoint.get('best_psnr', 0.0)\n","                    print(f\"Resumed training from epoch {start_epoch}\")\n","                else:\n","                    # Old format - direct model state dict\n","                    model.load_state_dict(checkpoint)\n","                    print(\"Loaded model weights (old format)\")\n","            else:\n","                # Very old format - direct model state dict\n","                model.load_state_dict(checkpoint)\n","                print(\"Loaded model weights (very old format)\")\n","\n","        except Exception as e:\n","            print(f\"Error loading checkpoint: {e}\")\n","            print(\"Starting training from scratch...\")\n","            start_epoch = 0\n","    else:\n","        print(\"No checkpoint found, starting training from scratch...\")\n","\n","    # ---- Train for 40 epochs before pruning ----\n","    print(f\"Starting training for {EPOCHS} epochs to get a well-trained model before pruning...\")\n","\n","    for epoch in range(start_epoch, EPOCHS):\n","        train_loss, train_psnr, train_l1, train_ssim, train_mse = train_one_epoch(model, train_loader, opt, DEVICE, epoch)\n","        val_loss, val_psnr, val_l1, val_ssim, val_mse = validate(model, val_loader, DEVICE, epoch)\n","\n","        print(f\"[PrePrune] Epoch {epoch+1}/{EPOCHS} | \"\n","              f\"Train Loss: {train_loss:.4f} PSNR: {train_psnr:.4f} | \"\n","              f\"Val Loss: {val_loss:.4f} PSNR: {val_psnr:.4f}\")\n","\n","        # Log to wandb\n","        wandb.log({\n","            \"epoch\": epoch + 1,\n","            \"train_loss\": train_loss,\n","            \"train_psnr\": train_psnr,\n","            \"train_l1\": train_l1,\n","            \"train_ssim\": train_ssim,\n","            \"train_mse\": train_mse,\n","            \"val_loss\": val_loss,\n","            \"val_psnr\": val_psnr,\n","            \"val_l1\": val_l1,\n","            \"val_ssim\": val_ssim,\n","            \"val_mse\": val_mse,\n","        })\n","\n","        # Save best model during pre-pruning training\n","        if val_psnr > BEST_PSNR:\n","            BEST_PSNR = val_psnr\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': opt.state_dict(),\n","                'best_psnr': BEST_PSNR,\n","                'loss': val_loss,\n","            }, os.path.join(SAVE_PATH, \"best_preprune_model.pth\"))\n","            print(f\"Saved best pre-prune model with PSNR {BEST_PSNR:.4f}\")\n","\n","        # Save checkpoint every 10 epochs\n","        if (epoch + 1) % 10 == 0:\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': opt.state_dict(),\n","                'best_psnr': BEST_PSNR,\n","                'loss': val_loss,\n","            }, os.path.join(SAVE_PATH, f\"checkpoint_epoch_{epoch+1}.pth\"))\n","\n","    # Save final pre-prune model\n","    torch.save({\n","        'epoch': EPOCHS,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': opt.state_dict(),\n","        'best_psnr': BEST_PSNR,\n","        'loss': val_loss,\n","    }, checkpoint_final)\n","    print(f\"Completed {EPOCHS} epochs of pre-pruning training. Final PSNR: {BEST_PSNR:.4f}\")\n","\n","    # ---- Apply pruning ----\n","    print(\"Applying pruning to model...\")\n","    apply_global_unstructured_pruning(model, amount=PRUNE_AMOUNT)\n","\n","    # Calculate and log sparsity\n","    total_zeros = 0\n","    total_params = 0\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Conv2d):\n","            w = module.weight.detach()\n","            total_zeros += torch.sum(w == 0).item()\n","            total_params += w.numel()\n","\n","    sparsity_after_mask = total_zeros / total_params\n","    print(f\"Global sparsity after mask applied: {total_zeros}/{total_params} = {sparsity_after_mask:.2%}\")\n","\n","    # Log sparsity to wandb\n","    wandb.log({\n","        \"pruning_sparsity_after_mask\": sparsity_after_mask,\n","        \"pruning_total_zeros\": total_zeros,\n","        \"pruning_total_params\": total_params\n","    })\n","\n","    # Make pruning permanent (removes hooks and masks)\n","    remove_pruning_reparametrization(model)\n","\n","    # Confirm zeros after removal\n","    total_zeros = 0\n","    total_params = 0\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Conv2d):\n","            w = module.weight.detach()\n","            total_zeros += torch.sum(w == 0).item()\n","            total_params += w.numel()\n","\n","    final_sparsity = total_zeros / total_params\n","    print(f\"Global sparsity after remove(): {total_zeros}/{total_params} = {final_sparsity:.2%}\")\n","\n","    # Log final sparsity\n","    wandb.log({\n","        \"pruning_final_sparsity\": final_sparsity\n","    })\n","\n","    # ---- Fine-tune the pruned model ----\n","    print(\"Fine-tuning pruned model...\")\n","    # Lower LR for fine-tune and reset optimizer\n","    opt = torch.optim.AdamW(model.parameters(), lr=LR*0.5, weight_decay=1e-6)\n","    finetune_best_psnr = 0.0\n","\n","    for epoch in range(FINETUNE_EPOCHS):\n","        train_loss, train_psnr, train_l1, train_ssim, train_mse = train_one_epoch(model, train_loader, opt, DEVICE, epoch)\n","        val_loss, val_psnr, val_l1, val_ssim, val_mse = validate(model, val_loader, DEVICE, epoch)\n","\n","        print(f\"[FineTune] Epoch {epoch+1}/{FINETUNE_EPOCHS} | \"\n","              f\"Train Loss: {train_loss:.4f} PSNR: {train_psnr:.4f} | \"\n","              f\"Val Loss: {val_loss:.4f} PSNR: {val_psnr:.4f}\")\n","\n","        # Log fine-tuning metrics to wandb\n","        wandb.log({\n","            \"finetune_epoch\": epoch + 1,\n","            \"finetune_train_loss\": train_loss,\n","            \"finetune_train_psnr\": train_psnr,\n","            \"finetune_train_l1\": train_l1,\n","            \"finetune_train_ssim\": train_ssim,\n","            \"finetune_train_mse\": train_mse,\n","            \"finetune_val_loss\": val_loss,\n","            \"finetune_val_psnr\": val_psnr,\n","            \"finetune_val_l1\": val_l1,\n","            \"finetune_val_ssim\": val_ssim,\n","            \"finetune_val_mse\": val_mse,\n","        })\n","\n","        # save best fine-tuned model\n","        if val_psnr > finetune_best_psnr:\n","            finetune_best_psnr = val_psnr\n","            torch.save(model.state_dict(), os.path.join(SAVE_PATH, \"best_pruned_model.pth\"))\n","            print(f\"Saved best pruned model with PSNR {finetune_best_psnr:.4f}\")\n","\n","            # Log best PSNR\n","            wandb.log({\"best_finetune_psnr\": finetune_best_psnr})\n","\n","    # Final save\n","    torch.save(model.state_dict(), os.path.join(SAVE_PATH, \"final_pruned_model.pth\"))\n","    print(\"Saved final pruned model.\")\n","\n","    # ---- Export to TorchScript for edge deployment ----\n","    print(\"Exporting to TorchScript (script mode)...\")\n","    model.eval()\n","    example = torch.randn(1, 3, 256, 256).to(DEVICE)\n","    try:\n","        scripted = torch.jit.trace(model, example)   # tracing is usually fine for deterministic nets\n","        ts_path = os.path.join(SAVE_PATH, \"model_pruned_scripted.pt\")\n","        scripted.save(ts_path)\n","        print(f\"Exported TorchScript to {ts_path}\")\n","\n","        # Log TorchScript export success\n","        wandb.log({\"torchscript_export\": \"success\"})\n","    except Exception as e:\n","        print(\"TorchScript tracing failed:\", e)\n","        try:\n","            scripted = torch.jit.script(model)\n","            ts_path = os.path.join(SAVE_PATH, \"model_pruned_scripted.pt\")\n","            scripted.save(ts_path)\n","            print(f\"Exported TorchScript (script) to {ts_path}\")\n","            wandb.log({\"torchscript_export\": \"success_script\"})\n","        except Exception as e2:\n","            print(\"TorchScript script failed:\", e2)\n","            print(\"Skipping TorchScript export.\")\n","            wandb.log({\"torchscript_export\": \"failed\"})\n","\n","    # Finish wandb run\n","    wandb.finish()\n","    print(\"All done. Training completed for 40 epochs + fine-tuning.\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"YdCGrCuE3DsX","executionInfo":{"status":"ok","timestamp":1759063797212,"user_tz":-330,"elapsed":5739843,"user":{"displayName":"Sadiq Pathan","userId":"17880434745985997358"}},"outputId":"5741f19d-bd89-40fb-d729-21b66b353d1f"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing previous runs because reinit is set to 'default'."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">40_epochs_denoise_prune</strong> at: <a href='https://wandb.ai/01fe22bci027-kle-tech/sdp_project2/runs/b3bzjzbs' target=\"_blank\">https://wandb.ai/01fe22bci027-kle-tech/sdp_project2/runs/b3bzjzbs</a><br> View project at: <a href='https://wandb.ai/01fe22bci027-kle-tech/sdp_project2' target=\"_blank\">https://wandb.ai/01fe22bci027-kle-tech/sdp_project2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250928_111004-b3bzjzbs/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.4"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250928_111417-kfio5m36</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/01fe22bci027-kle-tech/sdp_project2/runs/kfio5m36' target=\"_blank\">40_epochs_denoise_prune</a></strong> to <a href='https://wandb.ai/01fe22bci027-kle-tech/sdp_project2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/01fe22bci027-kle-tech/sdp_project2' target=\"_blank\">https://wandb.ai/01fe22bci027-kle-tech/sdp_project2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/01fe22bci027-kle-tech/sdp_project2/runs/kfio5m36' target=\"_blank\">https://wandb.ai/01fe22bci027-kle-tech/sdp_project2/runs/kfio5m36</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Found pre-prune checkpoint, loading...\n","Loaded model weights (old format)\n","Starting training for 40 epochs to get a well-trained model before pruning...\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.97s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.43s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 1/40 | Train Loss: 0.2262 PSNR: 14.0957 | Val Loss: 0.1964 PSNR: 15.0368\n","Saved best pre-prune model with PSNR 15.0368\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:45<00:00,  5.86s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.16s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 2/40 | Train Loss: 0.1987 PSNR: 14.5756 | Val Loss: 0.1833 PSNR: 15.2015\n","Saved best pre-prune model with PSNR 15.2015\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.96s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.45s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 3/40 | Train Loss: 0.1866 PSNR: 14.8267 | Val Loss: 0.1732 PSNR: 15.3120\n","Saved best pre-prune model with PSNR 15.3120\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.95s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.44s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 4/40 | Train Loss: 0.1786 PSNR: 14.8543 | Val Loss: 0.1666 PSNR: 15.3673\n","Saved best pre-prune model with PSNR 15.3673\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.95s/it]\n","Val: 100%|██████████| 2/2 [00:13<00:00,  6.52s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 5/40 | Train Loss: 0.1726 PSNR: 14.7976 | Val Loss: 0.1623 PSNR: 15.4225\n","Saved best pre-prune model with PSNR 15.4225\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:45<00:00,  5.86s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 6/40 | Train Loss: 0.1693 PSNR: 14.9380 | Val Loss: 0.1589 PSNR: 15.4613\n","Saved best pre-prune model with PSNR 15.4613\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.89s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.36s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 7/40 | Train Loss: 0.1676 PSNR: 14.9960 | Val Loss: 0.1567 PSNR: 15.4917\n","Saved best pre-prune model with PSNR 15.4917\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.94s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.42s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 8/40 | Train Loss: 0.1635 PSNR: 14.9131 | Val Loss: 0.1539 PSNR: 15.5226\n","Saved best pre-prune model with PSNR 15.5226\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.92s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.40s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 9/40 | Train Loss: 0.1610 PSNR: 15.1390 | Val Loss: 0.1512 PSNR: 15.8135\n","Saved best pre-prune model with PSNR 15.8135\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:45<00:00,  5.87s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.21s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 10/40 | Train Loss: 0.0968 PSNR: 20.8402 | Val Loss: 0.0635 PSNR: 24.7798\n","Saved best pre-prune model with PSNR 24.7798\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:45<00:00,  5.88s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.49s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 11/40 | Train Loss: 0.0551 PSNR: 25.7819 | Val Loss: 0.0515 PSNR: 25.8373\n","Saved best pre-prune model with PSNR 25.8373\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.92s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.44s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 12/40 | Train Loss: 0.0483 PSNR: 26.7621 | Val Loss: 0.0487 PSNR: 26.1790\n","Saved best pre-prune model with PSNR 26.1790\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.91s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.49s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 13/40 | Train Loss: 0.0471 PSNR: 26.8939 | Val Loss: 0.0497 PSNR: 25.9680\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.92s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.24s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 14/40 | Train Loss: 0.0468 PSNR: 26.8583 | Val Loss: 0.0478 PSNR: 26.4031\n","Saved best pre-prune model with PSNR 26.4031\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:45<00:00,  5.85s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.49s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 15/40 | Train Loss: 0.0426 PSNR: 27.6867 | Val Loss: 0.0442 PSNR: 26.9364\n","Saved best pre-prune model with PSNR 26.9364\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.93s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.40s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 16/40 | Train Loss: 0.0407 PSNR: 27.9820 | Val Loss: 0.0422 PSNR: 27.1817\n","Saved best pre-prune model with PSNR 27.1817\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.94s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.43s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 17/40 | Train Loss: 0.0388 PSNR: 28.3912 | Val Loss: 0.0410 PSNR: 27.3576\n","Saved best pre-prune model with PSNR 27.3576\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.90s/it]\n","Val: 100%|██████████| 2/2 [00:11<00:00,  6.00s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 18/40 | Train Loss: 0.0383 PSNR: 28.5038 | Val Loss: 0.0397 PSNR: 27.6181\n","Saved best pre-prune model with PSNR 27.6181\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.91s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.38s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 19/40 | Train Loss: 0.0375 PSNR: 28.4885 | Val Loss: 0.0388 PSNR: 27.7901\n","Saved best pre-prune model with PSNR 27.7901\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.97s/it]\n","Val: 100%|██████████| 2/2 [00:13<00:00,  6.57s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 20/40 | Train Loss: 0.0362 PSNR: 28.9255 | Val Loss: 0.0387 PSNR: 27.7827\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.94s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.35s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 21/40 | Train Loss: 0.0355 PSNR: 29.0194 | Val Loss: 0.0384 PSNR: 28.0537\n","Saved best pre-prune model with PSNR 28.0537\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:48<00:00,  6.03s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.42s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 22/40 | Train Loss: 0.0351 PSNR: 29.0802 | Val Loss: 0.0370 PSNR: 28.1900\n","Saved best pre-prune model with PSNR 28.1900\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:45<00:00,  5.86s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.40s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 23/40 | Train Loss: 0.0351 PSNR: 29.0022 | Val Loss: 0.0383 PSNR: 27.9700\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.94s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.44s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 24/40 | Train Loss: 0.0349 PSNR: 29.0645 | Val Loss: 0.0361 PSNR: 28.3513\n","Saved best pre-prune model with PSNR 28.3513\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.93s/it]\n","Val: 100%|██████████| 2/2 [00:13<00:00,  6.50s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 25/40 | Train Loss: 0.0333 PSNR: 29.5149 | Val Loss: 0.0353 PSNR: 28.4754\n","Saved best pre-prune model with PSNR 28.4754\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.97s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.46s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 26/40 | Train Loss: 0.0333 PSNR: 29.5424 | Val Loss: 0.0362 PSNR: 28.2715\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.89s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 27/40 | Train Loss: 0.0330 PSNR: 29.5879 | Val Loss: 0.0355 PSNR: 28.4004\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:48<00:00,  6.03s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.30s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 28/40 | Train Loss: 0.0329 PSNR: 29.6924 | Val Loss: 0.0339 PSNR: 28.8647\n","Saved best pre-prune model with PSNR 28.8647\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  6.00s/it]\n","Val: 100%|██████████| 2/2 [00:13<00:00,  6.55s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 29/40 | Train Loss: 0.0316 PSNR: 29.8908 | Val Loss: 0.0344 PSNR: 28.7373\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:48<00:00,  6.01s/it]\n","Val: 100%|██████████| 2/2 [00:13<00:00,  6.57s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 30/40 | Train Loss: 0.0318 PSNR: 29.8855 | Val Loss: 0.0336 PSNR: 28.7977\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.97s/it]\n","Val: 100%|██████████| 2/2 [00:13<00:00,  6.56s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 31/40 | Train Loss: 0.0321 PSNR: 29.7602 | Val Loss: 0.0340 PSNR: 28.7884\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.95s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 32/40 | Train Loss: 0.0311 PSNR: 30.0896 | Val Loss: 0.0345 PSNR: 28.7588\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.95s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.24s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 33/40 | Train Loss: 0.0314 PSNR: 30.0809 | Val Loss: 0.0348 PSNR: 28.8132\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:45<00:00,  5.85s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.43s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 34/40 | Train Loss: 0.0311 PSNR: 29.9849 | Val Loss: 0.0318 PSNR: 29.3401\n","Saved best pre-prune model with PSNR 29.3401\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.93s/it]\n","Val: 100%|██████████| 2/2 [00:13<00:00,  6.52s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 35/40 | Train Loss: 0.0292 PSNR: 30.5972 | Val Loss: 0.0311 PSNR: 29.3893\n","Saved best pre-prune model with PSNR 29.3893\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.93s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.48s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 36/40 | Train Loss: 0.0291 PSNR: 30.5405 | Val Loss: 0.0314 PSNR: 29.4426\n","Saved best pre-prune model with PSNR 29.4426\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.93s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.31s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 37/40 | Train Loss: 0.0288 PSNR: 30.5855 | Val Loss: 0.0310 PSNR: 29.5023\n","Saved best pre-prune model with PSNR 29.5023\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.89s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.13s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 38/40 | Train Loss: 0.0286 PSNR: 30.6543 | Val Loss: 0.0309 PSNR: 29.4685\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.97s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.46s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 39/40 | Train Loss: 0.0284 PSNR: 30.6066 | Val Loss: 0.0317 PSNR: 29.1102\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.95s/it]\n","Val: 100%|██████████| 2/2 [00:13<00:00,  6.50s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[PrePrune] Epoch 40/40 | Train Loss: 0.0288 PSNR: 30.4264 | Val Loss: 0.0300 PSNR: 29.6714\n","Saved best pre-prune model with PSNR 29.6714\n","Completed 40 epochs of pre-pruning training. Final PSNR: 29.6714\n","Applying pruning to model...\n","Applying global unstructured L1 pruning to 57 conv layers with amount=0.5\n","Global sparsity after mask applied: 498294/996588 = 50.00%\n","Global sparsity after remove(): 498294/996588 = 50.00%\n","Fine-tuning pruned model...\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:47<00:00,  5.97s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.36s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[FineTune] Epoch 1/8 | Train Loss: 0.0303 PSNR: 30.2070 | Val Loss: 0.0306 PSNR: 29.5872\n","Saved best pruned model with PSNR 29.5872\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.92s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.34s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[FineTune] Epoch 2/8 | Train Loss: 0.0276 PSNR: 30.8619 | Val Loss: 0.0297 PSNR: 29.7469\n","Saved best pruned model with PSNR 29.7469\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.89s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[FineTune] Epoch 3/8 | Train Loss: 0.0272 PSNR: 30.7946 | Val Loss: 0.0297 PSNR: 29.8152\n","Saved best pruned model with PSNR 29.8152\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.92s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.40s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[FineTune] Epoch 4/8 | Train Loss: 0.0270 PSNR: 31.0230 | Val Loss: 0.0292 PSNR: 29.8404\n","Saved best pruned model with PSNR 29.8404\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.92s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.47s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[FineTune] Epoch 5/8 | Train Loss: 0.0269 PSNR: 31.0180 | Val Loss: 0.0293 PSNR: 29.8430\n","Saved best pruned model with PSNR 29.8430\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.93s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.39s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[FineTune] Epoch 6/8 | Train Loss: 0.0267 PSNR: 31.1363 | Val Loss: 0.0296 PSNR: 29.8245\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:45<00:00,  5.86s/it]\n","Val: 100%|██████████| 2/2 [00:11<00:00,  5.98s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[FineTune] Epoch 7/8 | Train Loss: 0.0266 PSNR: 31.0484 | Val Loss: 0.0290 PSNR: 29.9026\n","Saved best pruned model with PSNR 29.9026\n"]},{"output_type":"stream","name":"stderr","text":["Train: 100%|██████████| 18/18 [01:46<00:00,  5.89s/it]\n","Val: 100%|██████████| 2/2 [00:12<00:00,  6.43s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[FineTune] Epoch 8/8 | Train Loss: 0.0268 PSNR: 31.0438 | Val Loss: 0.0289 PSNR: 29.9524\n","Saved best pruned model with PSNR 29.9524\n","Saved final pruned model.\n","Exporting to TorchScript (script mode)...\n","Exported TorchScript to /content/checkpoints_pruned/model_pruned_scripted.pt\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_finetune_psnr</td><td>▁▄▅▆▆▇█</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>finetune_epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>finetune_train_l1</td><td>█▂▂▁▁▁▁▂</td></tr><tr><td>finetune_train_loss</td><td>█▃▂▂▂▁▁▁</td></tr><tr><td>finetune_train_mse</td><td>█▃▂▂▁▁▁▁</td></tr><tr><td>finetune_train_psnr</td><td>▁▆▅▇▇█▇▇</td></tr><tr><td>finetune_train_ssim</td><td>█▅▄▃▂▂▁▁</td></tr><tr><td>finetune_val_l1</td><td>█▄▄▂▂▅▂▁</td></tr><tr><td>finetune_val_loss</td><td>█▄▄▂▃▄▁▁</td></tr><tr><td>+17</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_finetune_psnr</td><td>29.95237</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>finetune_epoch</td><td>8</td></tr><tr><td>finetune_train_l1</td><td>0.0191</td></tr><tr><td>finetune_train_loss</td><td>0.02676</td></tr><tr><td>finetune_train_mse</td><td>0.00085</td></tr><tr><td>finetune_train_psnr</td><td>31.04383</td></tr><tr><td>finetune_train_ssim</td><td>0.051</td></tr><tr><td>finetune_val_l1</td><td>0.02046</td></tr><tr><td>finetune_val_loss</td><td>0.02891</td></tr><tr><td>+18</td><td>...</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">40_epochs_denoise_prune</strong> at: <a href='https://wandb.ai/01fe22bci027-kle-tech/sdp_project2/runs/kfio5m36' target=\"_blank\">https://wandb.ai/01fe22bci027-kle-tech/sdp_project2/runs/kfio5m36</a><br> View project at: <a href='https://wandb.ai/01fe22bci027-kle-tech/sdp_project2' target=\"_blank\">https://wandb.ai/01fe22bci027-kle-tech/sdp_project2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250928_111417-kfio5m36/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["All done. Training completed for 40 epochs + fine-tuning.\n"]}]},{"cell_type":"code","source":["!zip -r denoise_model.zip /content/checkpoints_pruned\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUmJ345w6GZz","executionInfo":{"status":"ok","timestamp":1759064016305,"user_tz":-330,"elapsed":4225,"user":{"displayName":"Sadiq Pathan","userId":"17880434745985997358"}},"outputId":"d0b7c848-af38-487b-9ddd-bb0f8d27e4ad"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/checkpoints_pruned/ (stored 0%)\n","  adding: content/checkpoints_pruned/best_pruned_model.pth (deflated 16%)\n","  adding: content/checkpoints_pruned/checkpoint_epoch_30.pth (deflated 14%)\n","  adding: content/checkpoints_pruned/final_preprune.pth (deflated 14%)\n","  adding: content/checkpoints_pruned/model_pruned_scripted.pt (deflated 17%)\n","  adding: content/checkpoints_pruned/checkpoint_epoch_10.pth (deflated 17%)\n","  adding: content/checkpoints_pruned/checkpoint_epoch_20.pth (deflated 15%)\n","  adding: content/checkpoints_pruned/final_pruned_model.pth (deflated 16%)\n","  adding: content/checkpoints_pruned/best_preprune_model.pth (deflated 14%)\n","  adding: content/checkpoints_pruned/checkpoint_epoch_40.pth (deflated 14%)\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"denoise_model.zip\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"UENzkr4FYrOS","executionInfo":{"status":"ok","timestamp":1759064074044,"user_tz":-330,"elapsed":70,"user":{"displayName":"Sadiq Pathan","userId":"17880434745985997358"}},"outputId":"388ee1d2-382b-4fb0-de19-bcd878f503dc"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_4383ffcb-cbf0-4403-936f-7932425d318d\", \"denoise_model.zip\", 72527905)"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"EqZxUiSzY6Va"},"execution_count":null,"outputs":[]}]}